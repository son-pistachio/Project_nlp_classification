{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import datetime\n",
    "import yaml\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizerFast, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "if torch.__version__ >= '2.0':\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "num_seed = 42\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "def set_seed(seed: int):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    seed_everything(seed, workers=True)\n",
    "set_seed(num_seed)\n",
    "# YAML 파일에서 설정 읽기\n",
    "def load_config(yaml_file):\n",
    "    with open(yaml_file, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "        \n",
    "        lr = config['lr']\n",
    "        batch_size = config['batch_size']\n",
    "        max_epochs = config['max_epochs']\n",
    "        max_len = config['max_len']\n",
    "        num_classes = config['num_classes']\n",
    "    return float(lr), batch_size, max_epochs, max_len, num_classes\n",
    "\n",
    "lr, batch_size, max_epochs, max_len, num_classes = load_config('config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLightningModel(LightningModule):\n",
    "    def __init__(self, bert_pretrained, num_labels=num_classes, lr=lr, total_steps=None):\n",
    "        super(BertLightningModel, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.bert = BertModel.from_pretrained(bert_pretrained)\n",
    "        self.fc = nn.Linear(768, num_labels)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.total_steps = total_steps\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        cls_output = output.last_hidden_state[:, 0, :]\n",
    "        logits = self.fc(cls_output)\n",
    "        return logits\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self(**inputs)\n",
    "        loss = self.loss_fn(outputs, labels)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self(**inputs)\n",
    "        loss = self.loss_fn(outputs, labels)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        self.val_predictions.append(preds)\n",
    "        self.val_targets.append(labels)\n",
    "        self.val_losses.append(loss)\n",
    "    def on_validation_epoch_start(self):\n",
    "        self.val_predictions = []\n",
    "        self.val_targets = []\n",
    "        self.val_losses = []\n",
    "    def on_validation_epoch_end(self):\n",
    "        preds = torch.cat(self.val_predictions)\n",
    "        targets = torch.cat(self.val_targets)\n",
    "        loss = torch.mean(torch.stack(self.val_losses))\n",
    "        if self.trainer.world_size > 1:\n",
    "            preds = self.all_gather(preds)\n",
    "            targets = self.all_gather(targets)\n",
    "        preds = preds.cpu().numpy()\n",
    "        targets = targets.cpu().numpy()\n",
    "        acc = accuracy_score(targets, preds)\n",
    "        f1 = f1_score(targets, preds, average='macro')\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        self.log('val_f1', f1, prog_bar=True)\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self(**inputs)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        self.test_predictions.append(preds)\n",
    "        self.test_targets.append(labels)\n",
    "    def on_test_epoch_start(self):\n",
    "        self.test_predictions = []\n",
    "        self.test_targets = []\n",
    "    def on_test_epoch_end(self):\n",
    "        preds = torch.cat(self.test_predictions)\n",
    "        targets = torch.cat(self.test_targets)\n",
    "        if self.trainer.world_size > 1:\n",
    "            preds = self.all_gather(preds)\n",
    "            targets = self.all_gather(targets)\n",
    "        preds = preds.cpu().numpy()\n",
    "        targets = targets.cpu().numpy()\n",
    "        acc = accuracy_score(targets, preds)\n",
    "        f1 = f1_score(targets, preds, average='macro')\n",
    "        self.log('test_acc', acc)\n",
    "        self.log('test_f1', f1)\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=self.hparams.lr, correct_bias=False, no_deprecation_warning=True)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=0,\n",
    "            num_training_steps=self.trainer.estimated_stepping_batches\n",
    "        )\n",
    "        return [optimizer], [{'scheduler': scheduler, 'interval': 'step'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_NAME = 'kykim/bert-kor-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/son/anaconda3/envs/nlp/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/son/ml/nlp_classification/infer_datasets/A_W1_R.xlsx 파일에 예측 결과를 저장했습니다.\n",
      "/home/son/ml/nlp_classification/infer_datasets/E_W1_R.xlsx 파일에 예측 결과를 저장했습니다.\n",
      "/home/son/ml/nlp_classification/infer_datasets/C_W1_R.xlsx 파일에 예측 결과를 저장했습니다.\n",
      "/home/son/ml/nlp_classification/infer_datasets/F_W1_R.xlsx 파일에 예측 결과를 저장했습니다.\n",
      "/home/son/ml/nlp_classification/infer_datasets/H_W1_R.xlsx 파일에 예측 결과를 저장했습니다.\n",
      "/home/son/ml/nlp_classification/infer_datasets/B_W1_R.xlsx 파일에 예측 결과를 저장했습니다.\n",
      "/home/son/ml/nlp_classification/infer_datasets/I_W1_R.xlsx 파일에 예측 결과를 저장했습니다.\n",
      "/home/son/ml/nlp_classification/infer_datasets/J_W1_R.xlsx 파일에 예측 결과를 저장했습니다.\n",
      "/home/son/ml/nlp_classification/infer_datasets/G_W1_R.xlsx 파일에 예측 결과를 저장했습니다.\n",
      "/home/son/ml/nlp_classification/infer_datasets/D_W1_R.xlsx 파일에 예측 결과를 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizerFast\n",
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "label_mapping = {0: 'AS', 1: 'Q', 2: 'CL', 3: 'CP', 4: 'B'}\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 모델과 토크나이저 경로 설정\n",
    "best_model_path = '/home/son/ml/nlp_classification/Project_nlp_classification/best_class5/final_model.ckpt'\n",
    "CHECKPOINT_NAME = 'kykim/bert-kor-base'\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "bert_model = BertLightningModel.load_from_checkpoint(best_model_path)\n",
    "bert_model.eval()\n",
    "bert_model.to(device)\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(CHECKPOINT_NAME)\n",
    "\n",
    "# 폴더 경로와 파일 리스트 설정\n",
    "folder_path = '/home/son/ml/nlp_classification/infer_datasets'\n",
    "file_list = glob.glob(os.path.join(folder_path, '*.xlsx'))\n",
    "\n",
    "# 최대 시퀀스 길이와 배치 크기 설정\n",
    "max_len = 128\n",
    "batch_size = 16\n",
    "\n",
    "for file_path in file_list:\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    if 'Text' not in df.columns:\n",
    "        print(f\"'Text' 컬럼이 {file_path}에 없습니다.\")\n",
    "        continue\n",
    "    \n",
    "    texts = df['Text'].tolist()\n",
    "    \n",
    "    tokens = tokenizer(\n",
    "        texts,\n",
    "        return_tensors='pt',\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=max_len,\n",
    "        add_special_tokens=True\n",
    "    )\n",
    "    \n",
    "    input_ids = tokens['input_ids'].to(device)\n",
    "    attention_mask = tokens['attention_mask'].to(device)\n",
    "    token_type_ids = tokens['token_type_ids'].to(device)\n",
    "    \n",
    "    predicted_classes = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_input_ids = input_ids[i:i+batch_size]\n",
    "            batch_attention_mask = attention_mask[i:i+batch_size]\n",
    "            batch_token_type_ids = token_type_ids[i:i+batch_size]\n",
    "            \n",
    "            outputs = bert_model(\n",
    "                input_ids=batch_input_ids,\n",
    "                attention_mask=batch_attention_mask,\n",
    "                token_type_ids=batch_token_type_ids\n",
    "            )\n",
    "            \n",
    "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probabilities, dim=1).cpu().numpy()\n",
    "            predicted_classes.extend(preds)\n",
    "    \n",
    "    # 숫자 클래스를 레이블 문자열로 변환\n",
    "    predicted_labels = [label_mapping[pred] for pred in predicted_classes]\n",
    "    \n",
    "    df['Prediction'] = predicted_labels\n",
    "    df.to_excel(file_path, index=False)\n",
    "    \n",
    "    print(f\"{file_path} 파일에 예측 결과를 저장했습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
